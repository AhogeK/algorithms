<!-- TOC -->
* [动态规划（上）](#动态规划上)
  * [动态规划概述](#动态规划概述)
    * [例题讲解：LCR 125.斐波那契数](#例题讲解lcr-125斐波那契数)
      * [算法思路](#算法思路)
      * [代码实现](#代码实现)
      * [复杂度分析](#复杂度分析)
    * [「记忆化递归」与「动态规划」](#记忆化递归与动态规划)
      * [它们到底是什么关系](#它们到底是什么关系)
      * [什么时候更适合用记忆化递归？](#什么时候更适合用记忆化递归)
      * [什么时候更适合用循环 DP？](#什么时候更适合用循环-dp)
    * [可以使用「动态规划」解决的问题需要具备三个性质](#可以使用动态规划解决的问题需要具备三个性质)
      * [重复子问题：同一个小问题会被反复遇到](#重复子问题同一个小问题会被反复遇到)
      * [最优子结构：整体最优能由子问题最优拼出来](#最优子结构整体最优能由子问题最优拼出来)
      * [无后效性：未来只依赖“状态”，不依赖“状态怎么来的”](#无后效性未来只依赖状态不依赖状态怎么来的)
      * [怎么快速判断“这题像不像 DP”](#怎么快速判断这题像不像-dp)
      * [常见“看起来像 DP 但会翻车”的点](#常见看起来像-dp-但会翻车的点)
    * [动态规划的核心双剑：状态与状态转移方程](#动态规划的核心双剑状态与状态转移方程)
      * [**什么是"状态"？**](#什么是状态)
      * [⚡ **什么是"状态转移方程"？**](#-什么是状态转移方程)
      * [🛠️ **如何推导状态转移方程？**](#-如何推导状态转移方程)
      * [🎨 **实现方式对比**](#-实现方式对比)
<!-- TOC -->

# 动态规划（上）

> 动态规划（Dynamic Programming，简称 DP），听起来像是一种高深的“编程方式”，但它实际上是一种算法设计思想。

用一句话概括就是：**大事化小，小事化了，且绝不重复做同样的事。**

它核心的哲学是：**通过把原问题分解为相对简单的子问题的方式求解复杂问题**。但与“分治法”不同的是，这些子问题往往是**重叠**的，
动态规划会将每个子问题的解**存起来**（通常存在一个数组或哈希表中），当下次需要这个子问题的结果时，直接查表，而不是重新计算。

这是一种典型的**空间换时间**（Space for Time）的策略。

1. 通俗理解：1+1+1+1 的故事

   Quora 上有一个非常经典的解释：

   > **问：** 纸上写着 “ $1+1+1+1+1+1+1+1$”，问你结果是多少？\
   > **答：** 你数了一下，说是 $8$。
   >
   > **问：** 我在后面又加了一个 “ $+1$”，现在是多少？\
   > **答：** 你会立刻说是 $9$。
   >
   > **问：** 为什么你这次算出 $9$ 这么快？不需要重新数一遍前面的 $8$ 个 $1$ 吗？\
   > **答：** 因为我**记住了**前面的结果是 $8$，只需要 $8+1$ 就行了。

   这就是动态规划的核心：**记住所求过的解（Memoization/Tabulation），避免重复计算**。

2. 动态规划的两大核心性质

   如果一个问题能用动态规划解决，它通常具备以下两个特征：

   ① 重叠子问题 (Overlapping Subproblems)

   在求解过程中，同一个子问题会被多次调用。

    * **反例**：归并排序。虽然它分成了子数组，但左边的数组和右边的数组完全没关系，不重叠。这是“分治”。
    * **正例**：斐波那契数列。计算 $f(5)$ 需要 $f(4)$ 和 $f(3)$；计算 $f(6)$ 需要 $f(5)$ 和 $f(4)$。这里 $f(4)$ 就被重复利用了。

   ② 最优子结构 (Optimal Substructure)

   原问题的“最优解”包含其子问题的“最优解”。

    * **例子**：在这个图中求 $A \to C$ 的最短路径。如果最短路径经过 $B$，那么 $A \to B$ 的路径也必须是 $A$ 到 $B$ 之间的最短路径。
    * **意义**：我们可以通过组合子问题的最优解来构建原问题的最优解。

3. 解题四部曲

   做 DP 题时，通常按照这四个步骤思考：

    1. **定义状态（State Definition）：**\
       最重要的一步。你需要定义数组 `dp[i]` 或者 `dp[i][j]` 到底代表什么含义？

        * *例如：* `dp[i]` 表示爬到第 $i$ 阶楼梯的方法总数。

    2. **推导状态转移方程（State Transition Equation）：**\
       这是 DP 的灵魂。如何从已知的小规模状态推导出当前状态？

        * *例如：* 要到第 $i$ 阶，只能从第 $i-1$ 阶迈一步，或从 $i-2$ 阶迈两步。
        * 方程： $dp[i] = dp[i-1] + dp[i-2]$

    3. **初始化（Initialization/Base Case）：**\
       最基础的状态是多少？防止数组越界，也为递推提供起点。

        * *例如：* $dp = 0, dp = 1, dp = 2$。

    4. **确定遍历顺序（Traversal Order）：**\
       是从前向后算，还是从后向前算？

        * *例如：* 想算 $dp[i]$，必须先知道 $dp[i-1]$，所以要从 $i=3$ 开始从小到大遍历。

4. 举个例子：斐波那契数列

   计算第 $n$ 个斐波那契数。

   ❌ 暴力递归（Naive Recursion）

    ```
    int fib(int n) {
        if (n <= 1) return n;
        return fib(n - 1) + fib(n - 2);
    }
    ```

    * **问题**：计算 `fib(5)` 会计算 `fib(4)` 和 `fib(3)`，计算 `fib(4)` 又要算 `fib(3)`... `fib(3)` 被重复计算了多次。
    * **复杂度**：时间复杂度爆炸，约为 $\mathcal{O}(2^n)$。

   ✅ 动态规划（Dynamic Programming）

   我们开一个数组 `dp` 记录结果。

    ```
    int fib(int n) {
        if (n <= 1) return n;
        int[] dp = new int[n + 1];
        // 初始化
        dp[0] = 0;
        dp[1] = 1;
        // 状态转移
        for (int i = 2; i <= n; i++) {
            dp[i] = dp[i - 1] + dp[i - 2];
        }
        return dp[n];
    }
    ```

    * **优化**：每个状态只算一次。
    * **复杂度**：时间复杂度降为 $\mathcal{O}(n)$，空间复杂度 $\mathcal{O}(n)$（可进一步优化为 $\mathcal{O}(1)$）。

**当你发现一个问题可以分解，且分解后的子问题会重复出现时，请立刻想到：DP 大法好。**

## 动态规划概述

### 例题讲解：LCR 125.[斐波那契数](https://leetcode.cn/problems/fei-bo-na-qi-shu-lie-lcof)

#### 算法思路

1. **朴素递归（不推荐 ❌）**

   如果直接翻译公式写递归，计算 $F(n)$ 需要计算 $F(n-1)$ 和 $F(n-2)$
   ，这会产生大量的重复计算。时间复杂度是指数级的 $\mathcal{O}(2^n)$，对于 $n=100$ 绝对会超时。

2. **记忆化搜索（自顶向下 ✅）**

   使用一个数组记录已经计算过的 $F(n)$，避免重复计算。这可以将复杂度降为 $\mathcal{O}(n)$，但需要额外的栈空间。

3. **迭代动态规划（自底向上 ✅）**

   我们可以从 $F(0)$ 和 $F(1)$ 开始，逐步计算 $F(2), F(3), \dots, F(n)$。\
   状态转移方程为：

   $$dp[i] = (dp[i-1] + dp[i-2]) \pmod{1000000007}$$

   这也是题目要求的核心思路。

4. **滚动数组优化（执行最快 🚀）**

   观察上述转移方程，计算 $dp[i]$ 只需要用到 $dp[i-1]$ 和 $dp[i-2]$ 这两个状态。这意味着我们不需要维护一个长度为 $n+1$
   的数组，只需要 **两个变量** 滚动更新即可。

    * 设 $a$ 代表 $F(i-2)$
    * 设 $b$ 代表 $F(i-1)$
    * 计算 $sum = (a + b) \\% MOD$，这里的 $sum$ 就是 $F(i)$
    * **滚动更新**：下一次循环时，原先的 $F(i-1)$ 变为 $F(i-2)$，原先的 $F(i)$ 变为 $F(i-1)$
      。即： $a \leftarrow b$， $b \leftarrow sum$。

   这种方法将空间复杂度降低到了极致的 $\mathcal{O}(1)$。

**🗝️ 核心知识点与技巧**

* **动态规划 (DP)**：将大问题分解为重叠子问题，通过状态转移求解。
* **空间优化 (滚动数组)**：当状态转移只依赖于前几个状态时，可以使用有限的变量代替数组，极大地节省内存。
* **取模运算性质**： $(a + b) \pmod m = ((a \pmod m) + (b \pmod m)) \pmod m$。在本题中，由于中间结果不会超过
  `Integer.MAX_VALUE`，直接相加后取模即可。

#### 代码实现

```java
public class Fib {
    public int fib(int n) {
        if (n < 2) return n;
        int a = 0;
        int b = 1;
        final int MOD = 1000000007;
        for (int i = 2; i <= n; i++) {
            int sum = (a + b) % MOD;
            a = b;
            b = sum;
        }
        return b;
    }
}
```

#### 复杂度分析

* **时间复杂度**： $\mathcal{O}(n)$
    * 代码包含一个从 $2$ 到 $n$ 的循环，循环内部的操作（加法、取模、赋值）都是常数时间 $\mathcal{O}(1)$。因此总时间与 $n$ 成正比。
* **空间复杂度**： $\mathcal{O}(1)$
    * 我们只使用了 `a`, `b`, `sum`, `i` 等几个有限的变量，没有使用随 $n$ 增长的数组或递归栈空间。

### 「记忆化递归」与「动态规划」

> “记忆化递归”和“动态规划（DP）”本质上在做同一件事：把一个问题拆成重叠子问题，并把子问题答案缓存起来，避免重复计算。
> 它们最大的区别通常不在“思想”，而在“写法”和“计算顺序”。

#### 它们到底是什么关系

记忆化递归可以理解成“自顶向下的 DP”（Top-down DP）：你按人类直觉写递归，把每个状态的答案存进 `memo`，下次再遇到同一状态就直接返回。

动态规划（常指循环写法）更像“自底向上的 DP”（Bottom-up DP）：你先确定状态的计算顺序，用 `dp` 数组从小到大（或按拓扑序）把所有需要的状态填出来，最后取目标状态。

很多教材会说：

* 记忆化递归 = DP 思想 + 递归 + 缓存
* 循环 DP = DP 思想 + 表格填充（tabulation）

**一个最小例子：斐波那契**

递推关系是：

$f(n)=f(n-1)+f(n-2)$

*记忆化递归（Top-down）*

* 你只会计算“真正用到的状态”
* 但有函数调用开销，并且要吃递归栈深度（比如 $n$ 很大时可能爆栈）

```java
Long[] memo = new Long[N];

long f(int n) {
    if (n <= 1) return n;
    if (memo[n] != null) return memo[n];

    return memo[n] = f(n - 1) + f(n - 2); // 赋值并返回
}
```

*循环 DP（Bottom-up）*

* 状态计算顺序清晰，通常更稳
* 一般不会爆栈，常数也更小

```java
long f(int n) {
    if (n <= 1) return n;
    long dp0 = 0, dp1 = 1;
    for (int i = 2; i <= n; i++) {
        long sum = dp0 + dp1;
        dp0 = dp1;
        dp1 = sum;
    }
    return dp1;
}
```

两者时间复杂度都能做到 $\mathcal{O}(n)$；区别更多体现在工程表现（栈、常数、可控性）上。

#### 什么时候更适合用记忆化递归？

下面这些场景，记忆化递归往往更顺手，甚至更不容易写错：

* 状态转移天然是“从目标往回问”的，比如区间 DP、树形 DP、博弈 DP（从根/目标状态递归下去很自然）
* 可达状态很稀疏：理论上状态空间很大，但实际只会访问其中一小部分（Top-down 只算访问到的）
* 你一时难以确定一个好用的“填表顺序”（Bottom-up 需要确保依赖已算完）

#### 什么时候更适合用循环 DP？

循环 DP 通常更适合追求稳定和性能的场合：

* 依赖关系很规则（例如线性、网格、背包），填表顺序简单明确
* 数据规模大，递归层数可能很深（避免爆栈）
* 需要进一步优化（滚动数组、位运算优化、严格控制内存布局等）

**一个实用的判断标准**

*如果你已经写出了“状态 + 转移”，但还没想清楚遍历顺序，那就先写记忆化递归把逻辑跑通；等你确认依赖关系和访问范围后，再考虑把它“翻译”成循环
DP 来提速和增强鲁棒性。*

### 可以使用「动态规划」解决的问题需要具备三个性质

> 动态规划（DP）能“好用”的核心原因，是它把一个大问题拆成很多小问题，并且让这些小问题的答案可以**复用**、可以拼回大问题、
> 还不会因为“之前怎么走”而产生额外麻烦。通常我们用三个性质来判断：重复子问题、最优子结构、无后效性。

#### 重复子问题：同一个小问题会被反复遇到

所谓重复子问题，说的是你用朴素递归/搜索去做时，会在不同分支里多次算到“同一种状态”。既然会重复，就值得把答案缓存起来（记忆化）或按顺序填表（递推）。

经典例子是斐波那契数列：递归会反复计算同样的 $f[k]$。

$f[n] = f[n-1] + f[n-2]$

判断小技巧：如果你画出递归调用树/搜索树，发现很多节点“长得一样”（同一组参数、同一状态定义），那就是重复子问题的强信号。

#### 最优子结构：整体最优能由子问题最优拼出来

最优子结构指：一个问题的最优解中，包含的子结构（子路径、子区间、子集合等）本身也必须是对应子问题的最优解；否则你可以替换成更优子解，让整体更优，出现矛盾。

比如很多“最短路/最小代价”类转移都长这样：到达 $i$ 的最优值来自某个前驱 $j$ 的最优值再加一段代价。

$dp[i] = \min\limits_{j < i}\Big(dp[j] + cost(j,i)\Big)$

注意：最优子结构不是“任何拆法都行”，而是“存在一种合理拆法使得最优可由子最优组合”。像 0/1 背包也满足：选或不选第 $i$
件物品，把问题拆成规模更小的背包子问题。

#### 无后效性：未来只依赖“状态”，不依赖“状态怎么来的”

无后效性（也常被类比成“马尔可夫性”）指：当你把问题抽象成某个状态 $dp[\cdot]$ 后，后续决策只需要这个状态值，不需要额外追溯历史细节；换句话说，状态信息必须“足够完备”。

比如你定义 $dp[i]$ 表示“考虑到第 $i$ 步的最优值”，那么从 $dp[i]$ 转移到 $dp[i+1]$ 的规则，不能依赖“达到 $i$
时具体选了哪些东西但状态里没记录”。一旦依赖了，就会出事：同样的 $dp[i]$ 数值可能对应多种历史，而这些历史对未来可行性/收益不同，导致转移不正确。

常见修复方式是把“缺失的历史信息”塞进状态里：

* 需要知道“已经用过哪些元素” → 状态加上集合/位掩码
* 需要知道“上一个字符/上一个位置” → 状态加上 last
* 需要知道“某些资源剩余量” → 状态加上容量/次数等维度

#### 怎么快速判断“这题像不像 DP”

可以用下面这些问法去“拷打题目”，基本就能定位：

* 是否能写出“状态 + 转移”，并且转移会反复用到相同状态（像递归树大量重叠）？这对应**重复子问题**
* 全局最优是否可以由若干更小规模的最优结果组合得到，而不会要求子问题用“非最优解”来成全整体？这对应**最优子结构**
* 我定义的状态，是否已经包含了未来决策所需的一切信息？如果还要问“你之前具体怎么选的”，那就是违反**无后效性**，需要扩状态

#### 常见“看起来像 DP 但会翻车”的点

* 把状态定义得太粗：例如只记“走到第 $i$ 位的最优值”，但实际上未来可选项取决于“之前选过哪些/最后一次出现位置”等隐藏信息
* 问题本身要求“路径必须简单（不重复点）”“序列必须全局不冲突”等全局约束：这通常会迫使你把“已访问集合/冲突信息”纳入状态，否则就会有后效性
* 最优子结构被额外规则破坏：例如某些“局部最优的子段”并不一定能出现在全局最优里（常见于带复杂耦合约束的组合优化）

### 动态规划的核心双剑：状态与状态转移方程

> 动态规划（Dynamic Programming, DP）是将一个复杂问题拆解为若干子问题，通过解决子问题并保存结果来避免重复计算的优化方法。在这个过程中，
> 最关键的就是**状态**和**状态转移方程**这两个概念。

#### **什么是"状态"？**

**状态**是对问题在某个特定阶段的描述，用变量来表示问题发展到不同阶段时的客观情况。简单理解：

> 状态就是把原问题和子问题中**会变化的量**找出来，用它们来标记问题的不同阶段

举几个例子理解 ✨：

* **斐波那契数列**：状态是"第 `n` 项"，用 `F(n)` 表示
* **爬楼梯问题**：状态是"爬到第 `i` 阶"，用 `dp[i]` 表示爬到第 `i` 阶的方法数
* **背包问题**：状态可能是"前 `i` 个物品、背包容量为 `j`"，用 `dp[i][j]` 表示

状态设计的好坏直接影响整个算法的复杂度和可行性。**找准状态变量**是动态规划的第一步，也是最需要思考的一步。

🔑 **状态的特性**

好的状态设计应该满足：

* **无后效性**（马尔可夫性）：当前状态一旦确定，就不受未来决策影响。换句话说，"只关注现在，不回头看"
* **阶段有序**：问题可以按时间或空间分成若干有序阶段，前一阶段为后一阶段提供信息

#### ⚡ **什么是"状态转移方程"？**

**状态转移方程**是描述不同状态之间关系的数学表达式，告诉我们如何从已知的子问题状态推导出当前问题的状态。

> 状态转移方程就是把"大问题的答案"和"小问题的答案"之间建立联系的桥梁 🌉

**经典例子**

**例1: 斐波那契数列**

* 状态：`F(n)` 表示第 `n` 个斐波那契数
* 状态转移方程： $F(n) = F(n-1) + F(n-2)$
* 边界条件： $F(0) = 0, \quad F(1) = 1$

**例2: 爬楼梯**

假设每次可以爬 1 阶或 2 阶，问爬到第 `n` 阶有多少种方法？

* 状态：`dp[i]` 表示爬到第 `i` 阶的方法总数
* 状态转移方程： $\text{dp}[i] = \text{dp}[i-1] + \text{dp}[i-2]$
* 含义：爬到第 `i` 阶，要么从第 `i-1` 阶爬 1 步，要么从第 `i-2` 阶爬 2 步

**例3: 最大子数组和（Maximum Subarray）**

给定数组 `nums`，找连续子数组的最大和。

* 状态：`dp[i]` 表示以 `nums[i]` 结尾的最大子数组和
* 状态转移方程： $\text{dp}[i] = \max(\text{dp}[i-1] + \text{nums}[i], \text{nums}[i])$
* 含义：当前位置的最大和，要么是"之前的最大和+当前元素"，要么是"从当前元素重新开始"

**例4: 最长递增子序列（LIS）**

找数组中最长递增子序列的长度。

* 状态：`dp[i]` 表示以第 `i` 个元素结尾的最长递增子序列长度
* 状态转移方程： $\text{dp}[i] = \max\limits_{0 \le j < i, \, \text{nums}[j] < \text{nums}[i]} (\text{dp}[j] + 1)$
* 含义：遍历 `i` 之前的所有元素 `j`，如果 `nums[j] < nums[i]`，就可以把 `nums[i]` 接到以 `nums[j]` 结尾的序列后面

#### 🛠️ **如何推导状态转移方程？**

推导状态转移方程的一般步骤：

1. **定义状态**：明确用什么变量表示子问题
2. **分析决策**：思考当前状态可以从哪些子状态转移而来
3. **建立关系**：用数学式子把当前状态和子状态联系起来
4. **确定边界**：设定初始条件（最小规模子问题的答案）

| 步骤       | 爬楼梯示例                       | 最大子数组和示例                                |
|----------|-----------------------------|-----------------------------------------|
| **定义状态** | `dp[i]` = 爬到第 `i` 阶的方法数     | `dp[i]` = 以 `nums[i]` 结尾的最大和            |
| **分析决策** | 可以从 `i-1` 或 `i-2` 到达        | 可以延续之前的和，或重新开始                          |
| **建立关系** | `dp[i] = dp[i-1] + dp[i-2]` | `dp[i] = max(dp[i-1]+nums[i], nums[i])` |
| **确定边界** | `dp[0] = 1, dp[1] = 1`      | `dp[0] = nums[0]`                       |

#### 🎨 **实现方式对比**

动态规划有两种实现方式：

| 方式       | 别名    | 特点                | 适用场景      |
|----------|-------|-------------------|-----------|
| **自顶向下** | 记忆化递归 | 从原问题出发递归，用备忘录避免重复 | 思路自然，调试方便 |
| **自底向上** | 递推/迭代 | 从最小子问题开始，逐步推导     | 效率更高，节省空间 |

**代码示例（以斐波那契为例）**

**自顶向下（记忆化递归）**：

```java
// Logic for Top-Down approach
Map<Integer, Integer> memo = new HashMap<>();

int fib(int n) {
    if (n <= 1) return n;
    if (memo.containsKey(n)) return memo.get(n);

    int result = fib(n - 1) + fib(n - 2);
    memo.put(n, result);
    return result;
}
```

**自底向上（递推）**：

```java
// Logic for Bottom-Up approach
int fib(int n) {
    if (n <= 1) return n;

    int[] dp = new int[n + 1];
    dp[1] = 1;

    for (int i = 2; i <= n; i++) {
        dp[i] = dp[i - 1] + dp[i - 2];
    }

    return dp[n];
}
```

***

[返回](../README.md)